{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bfgn5ah6iyGb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a26OijY1jGcD"
      },
      "outputs": [],
      "source": [
        "df=pd.read_excel('Urban_traffic_complete.xlsx', sheet_name=\"Sheet1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "collapsed": true,
        "id": "psjVYifjjzkH",
        "outputId": "9edc7a27-e4b1-4425-e79d-b2c3e944984d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>record_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>intersection_id</th>\n",
              "      <th>intersection_name</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>vehicle_count</th>\n",
              "      <th>average_speed</th>\n",
              "      <th>signal_cycle_time</th>\n",
              "      <th>green_time</th>\n",
              "      <th>...</th>\n",
              "      <th>red_time</th>\n",
              "      <th>weather_condition</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>event</th>\n",
              "      <th>pollution_level</th>\n",
              "      <th>car_count</th>\n",
              "      <th>bus_count</th>\n",
              "      <th>truck_count</th>\n",
              "      <th>motorcycle_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>Civil Lines</td>\n",
              "      <td>25.4486</td>\n",
              "      <td>81.8333</td>\n",
              "      <td>51</td>\n",
              "      <td>46.52</td>\n",
              "      <td>120</td>\n",
              "      <td>63</td>\n",
              "      <td>...</td>\n",
              "      <td>53</td>\n",
              "      <td>Clear</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>New Year Celebration</td>\n",
              "      <td>0.84</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>Katra</td>\n",
              "      <td>25.4550</td>\n",
              "      <td>81.8463</td>\n",
              "      <td>73</td>\n",
              "      <td>38.59</td>\n",
              "      <td>120</td>\n",
              "      <td>57</td>\n",
              "      <td>...</td>\n",
              "      <td>59</td>\n",
              "      <td>Clear</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>New Year Celebration</td>\n",
              "      <td>1.54</td>\n",
              "      <td>38</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>3</td>\n",
              "      <td>Chowk</td>\n",
              "      <td>25.4314</td>\n",
              "      <td>81.8437</td>\n",
              "      <td>65</td>\n",
              "      <td>38.61</td>\n",
              "      <td>120</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>Clear</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>unknown</td>\n",
              "      <td>1.05</td>\n",
              "      <td>41</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>4</td>\n",
              "      <td>Tagore Town</td>\n",
              "      <td>25.4675</td>\n",
              "      <td>81.8867</td>\n",
              "      <td>54</td>\n",
              "      <td>44.05</td>\n",
              "      <td>120</td>\n",
              "      <td>58</td>\n",
              "      <td>...</td>\n",
              "      <td>58</td>\n",
              "      <td>Clear</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>unknown</td>\n",
              "      <td>1.18</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>5</td>\n",
              "      <td>Naini Bridge</td>\n",
              "      <td>25.4088</td>\n",
              "      <td>81.8592</td>\n",
              "      <td>30</td>\n",
              "      <td>49.09</td>\n",
              "      <td>120</td>\n",
              "      <td>59</td>\n",
              "      <td>...</td>\n",
              "      <td>58</td>\n",
              "      <td>Clear</td>\n",
              "      <td>Sunday</td>\n",
              "      <td>1</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0.44</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   record_id  timestamp  intersection_id intersection_name  latitude  \\\n",
              "0          1 2023-01-01                1       Civil Lines   25.4486   \n",
              "1          2 2023-01-01                2             Katra   25.4550   \n",
              "2          3 2023-01-01                3             Chowk   25.4314   \n",
              "3          4 2023-01-01                4       Tagore Town   25.4675   \n",
              "4          5 2023-01-01                5      Naini Bridge   25.4088   \n",
              "\n",
              "   longitude  vehicle_count  average_speed  signal_cycle_time  green_time  \\\n",
              "0    81.8333             51          46.52                120          63   \n",
              "1    81.8463             73          38.59                120          57   \n",
              "2    81.8437             65          38.61                120          58   \n",
              "3    81.8867             54          44.05                120          58   \n",
              "4    81.8592             30          49.09                120          59   \n",
              "\n",
              "   ...  red_time  weather_condition day_of_week is_holiday  \\\n",
              "0  ...        53              Clear      Sunday          1   \n",
              "1  ...        59              Clear      Sunday          1   \n",
              "2  ...        57              Clear      Sunday          1   \n",
              "3  ...        58              Clear      Sunday          1   \n",
              "4  ...        58              Clear      Sunday          1   \n",
              "\n",
              "                  event pollution_level  car_count  bus_count  truck_count  \\\n",
              "0  New Year Celebration            0.84         34          3            4   \n",
              "1  New Year Celebration            1.54         38          7           10   \n",
              "2               unknown            1.05         41          3            6   \n",
              "3               unknown            1.18         36          7            5   \n",
              "4               unknown            0.44         20          0            4   \n",
              "\n",
              "   motorcycle_count  \n",
              "0                10  \n",
              "1                18  \n",
              "2                15  \n",
              "3                 6  \n",
              "4                 6  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head() # just to check if data is uploaded or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "collapsed": true,
        "id": "CXb8VNXhkmB7",
        "outputId": "c6404b5c-e0d5-4606-ae32-6fb652b489fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "record_id            0.0\n",
              "timestamp            0.0\n",
              "intersection_id      0.0\n",
              "intersection_name    0.0\n",
              "latitude             0.0\n",
              "longitude            0.0\n",
              "vehicle_count        0.0\n",
              "average_speed        0.0\n",
              "signal_cycle_time    0.0\n",
              "green_time           0.0\n",
              "yellow_time          0.0\n",
              "red_time             0.0\n",
              "weather_condition    0.0\n",
              "day_of_week          0.0\n",
              "is_holiday           0.0\n",
              "event                0.0\n",
              "pollution_level      0.0\n",
              "car_count            0.0\n",
              "bus_count            0.0\n",
              "truck_count          0.0\n",
              "motorcycle_count     0.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#finding percentage of null values so as to  decide which method to use to fill the null data\n",
        "df.isnull().sum()/len(df) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "collapsed": true,
        "id": "dYx6NWGVkL2c",
        "outputId": "9c0a4aa1-6af7-4e67-8617-a53209361a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "record_id            0\n",
              "timestamp            0\n",
              "intersection_id      0\n",
              "intersection_name    0\n",
              "latitude             0\n",
              "longitude            0\n",
              "vehicle_count        0\n",
              "average_speed        0\n",
              "signal_cycle_time    0\n",
              "green_time           0\n",
              "yellow_time          0\n",
              "red_time             0\n",
              "weather_condition    0\n",
              "day_of_week          0\n",
              "is_holiday           0\n",
              "event                0\n",
              "pollution_level      0\n",
              "car_count            0\n",
              "bus_count            0\n",
              "truck_count          0\n",
              "motorcycle_count     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum() # finding total null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixi1zWKbmsbB"
      },
      "source": [
        "1. event (91.47%):\n",
        "-Method: Fill with \"No Event\"\n",
        "-Reason: High missing percentage\n",
        "\n",
        "2. intersection_name (1.16%):\n",
        "-method: Mode\n",
        "-Reason: Categorical field with low missing values.\n",
        "\n",
        "3. longitude (1.15%):\n",
        "-method  Median\n",
        "-Reason: Numeric spatial data hence keeps consistency.\n",
        "\n",
        "4. vehicle_count (1.11%):\n",
        "-method:  Median\n",
        "-Reason: Numeric with few missing values.\n",
        "\n",
        "5. signal_cycle_time (1.07%):\n",
        "-method  Median\n",
        "-Reason: Continuous numeric data with low null values.\n",
        "\n",
        "6. truck_count (1.05%):\n",
        "-method:  Median\n",
        "-Reason: Numeric vehicle count; low missing percentage.\n",
        "\n",
        "7. latitude (1.05%):\n",
        "-method:  Median\n",
        "-Reason: Spatial data; maintains geographic consistency.\n",
        "\n",
        "8. pollution_level (1.04%):\n",
        "-method Median\n",
        "-Reason: Continuous numeric data with low null values.\n",
        "\n",
        "9. is_holiday (1.03%):\n",
        "-method Fill with 0\n",
        "-Reason: Binary field; assuming non-holiday\n",
        "\n",
        "10. red_time (1.01%):\n",
        "-method Median\n",
        "-Reason: Numeric time data with minimal missing values.\n",
        "\n",
        "11. motorcycle_count (0.99%):\n",
        "-method  Median\n",
        "-Reason: Numeric count; keeps vehicle data consistent.\n",
        "\n",
        "12. record_id (0.97%):\n",
        "-method Drop rows if unique; else Mode\n",
        "-Reason: Identifier; drop if essential for uniqueness.\n",
        "\n",
        "13. timestamp (0.96%):\n",
        "-method :Interpolate\n",
        "-Reason: Important for time series\n",
        "\n",
        "14. car_count (0.96%):\n",
        "-method Median\n",
        "-Reason: Numeric vehicle count with few missing values.\n",
        "\n",
        "15. bus_count (0.94%):\n",
        "-method: Median\n",
        "-Reason: Numeric count; ensures consistent vehicle data.\n",
        "\n",
        "16. day_of_week (0.93%):\n",
        "-method Mode\n",
        "-Reason: Categorical; mode preserves weekday distribution.\n",
        "\n",
        "17. green_time (0.91%):\n",
        "-method Median\n",
        "-Reason: Numeric time data; keeps timing consistent.\n",
        "\n",
        "18. intersection_id (0.91%):\n",
        "-method Mode\n",
        "-Reason: Categorical ID; mode ensures consistency.\n",
        "\n",
        "19. yellow_time (0.88%):\n",
        "-method Median\n",
        "-Reason: Numeric timing data with low missing values.\n",
        "\n",
        "20. weather_condition (0.77%):\n",
        "-method Mode\n",
        "-Reason: Categorical; mode preserves distribution.\n",
        "\n",
        "21. average_speed (0.73%):\n",
        "-method  Median\n",
        "-Reason: Numeric data with very low null values.-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyTs9zSjlE2C",
        "outputId": "9b79086d-9f29-4eb3-e22c-0b81494b4de5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\3293179085.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(median_value, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "columns_to_fill=['longitude','vehicle_count','signal_cycle_time','truck_count','latitude','pollution_level','red_time','motorcycle_count','car_count','bus_count','green_time','yellow_time','average_speed']\n",
        "for column in columns_to_fill:\n",
        "    median_value = df[column].median()\n",
        "    df[column].fillna(median_value, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMvU-t5Z0qCG",
        "outputId": "6d510794-55cf-41af-d112-bcb917223add"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\963461900.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(mode_value, inplace=True)\n",
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\963461900.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[column].fillna(mode_value, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "columns_filling =['intersection_name','day_of_week','intersection_id','weather_condition']\n",
        "for column in columns_filling:\n",
        "    mode_value = df[column].mode()[0]\n",
        "    df[column].fillna(mode_value, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_dBYIYw85LjX"
      },
      "outputs": [],
      "source": [
        "#interpolating the time stamp\n",
        "# first making it in ascending order\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df.sort_values(by='timestamp', ascending=True, inplace=True)\n",
        "df['timestamp'] = df['timestamp'].interpolate(method='linear')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mDSn-go55_M8"
      },
      "outputs": [],
      "source": [
        "df['day_of_week'] = df['day_of_week'].fillna(df['timestamp'].dt.day_name()) # filling the day as per the date in the calendar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GslGpUDw9jp3"
      },
      "outputs": [],
      "source": [
        "df['is_holiday'] = np.where(df['timestamp'].dt.day_name() == 'Sunday', 1, 0)   #filling sunday as holiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DYGfsrub-Fq2"
      },
      "outputs": [],
      "source": [
        "df['event'] = df['event'].fillna('unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjE6doMb_GrS",
        "outputId": "20b7f161-d89c-4aaa-b3e8-6d45dd4359ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\2867517982.py:1: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df['record_id'] = df['record_id'].fillna(method='ffill')  # this is front filling as everythingas id were mentioned in asc order\n"
          ]
        }
      ],
      "source": [
        "df['record_id'] = df['record_id'].fillna(method='ffill')  # this is front filling as everythingas id were mentioned in asc order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "collapsed": true,
        "id": "Vrd9dRWhq9MK",
        "outputId": "742ad54c-b98f-4202-bde4-3f20eb2ea9a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "record_id            0\n",
              "timestamp            0\n",
              "intersection_id      0\n",
              "intersection_name    0\n",
              "latitude             0\n",
              "longitude            0\n",
              "vehicle_count        0\n",
              "average_speed        0\n",
              "signal_cycle_time    0\n",
              "green_time           0\n",
              "yellow_time          0\n",
              "red_time             0\n",
              "weather_condition    0\n",
              "day_of_week          0\n",
              "is_holiday           0\n",
              "event                0\n",
              "pollution_level      0\n",
              "car_count            0\n",
              "bus_count            0\n",
              "truck_count          0\n",
              "motorcycle_count     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()#checking if values are filled or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URF9kn-dB558"
      },
      "source": [
        "DETECTING OUTLIERS USING IQR METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF3oST0kCDkH",
        "outputId": "2e041516-81a5-4cb7-c18d-ce83e8068f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vehicle_count      0\n",
            "average_speed    146\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "columns_check = ['vehicle_count', 'average_speed']\n",
        "\n",
        "# DataFrame to store the outlier status\n",
        "iqr_outliers = pd.DataFrame(False, index=df.index, columns=columns_check)\n",
        "\n",
        "# Detect outliers for each specified column based on IQR\n",
        "for column in columns_check:\n",
        "    Q1 = df[column].quantile(0.25)  # First quartile (25th percentile)\n",
        "    Q3 = df[column].quantile(0.75)  # Third quartile (75th percentile)\n",
        "    IQR = Q3 - Q1                   # Interquartile Range (IQR)\n",
        "    lower_bound = Q1 - 1.5 * IQR    # Lower bound for outliers\n",
        "    upper_bound = Q3 + 1.5 * IQR    # Upper bound for outliers\n",
        "\n",
        "    # Mark True for values that are below the lower bound or above the upper bound\n",
        "    iqr_outliers[column] = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
        "\n",
        "# Count of outliers per specified column using IQR method\n",
        "iqr_outlier_counts = iqr_outliers.sum()\n",
        "print(iqr_outlier_counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2QeGRxuEc5j"
      },
      "source": [
        "Working with oulier using cap and floor approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ELJ898aMEivs"
      },
      "outputs": [],
      "source": [
        "def cap_floor(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Defining the cap and floor\n",
        "    cap = Q3 + 1.5 * IQR\n",
        "    floor = Q1 - 1.5 * IQR\n",
        "\n",
        "    # setting the values\n",
        "    df[column] = np.where(df[column] > cap, cap, df[column])\n",
        "    df[column] = np.where(df[column] < floor, floor, df[column])\n",
        "\n",
        "# applying the same as above\n",
        "cap_floor(df, 'vehicle_count')\n",
        "cap_floor(df, 'average_speed')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-t3SDIjEuNn",
        "outputId": "3012fcf1-4d21-4be6-ca87-d26010ee1986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vehicle_count      0\n",
            "average_speed    146\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(iqr_outlier_counts) # checking the outliers again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46WEdS3EoFWG"
      },
      "source": [
        "PYTHON SCRIPTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7kPlLkVgoG76",
        "outputId": "a1f67653-0dfa-49ec-8e20-3393ba532c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Vehicle Count per Day timestamp\n",
            "2023-01-01 00:00:00      613.0\n",
            "2023-01-01 00:10:00      535.0\n",
            "2023-01-01 00:20:00      491.0\n",
            "2023-01-01 00:30:00      645.0\n",
            "2023-01-01 00:40:00      480.0\n",
            "                        ...   \n",
            "2023-01-07 23:10:00      893.0\n",
            "2023-01-07 23:20:00      749.0\n",
            "2023-01-07 23:30:00      708.0\n",
            "2023-01-07 23:40:00      826.0\n",
            "2023-01-07 23:50:00    11496.0\n",
            "Name: vehicle_count, Length: 1008, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Total Vehicle Count per Day\n",
        "total_vehicle_count_per_day = df.groupby('timestamp')['vehicle_count'].sum()\n",
        "print(\"Total Vehicle Count per Day\", total_vehicle_count_per_day)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrXvICF_-NyB",
        "outputId": "7e2ae475-5fba-44c0-c165-5eb4a6162e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersection with Highest Average Vehicle Count Katra Highest Average Vehicle Count 112.46446446446447\n"
          ]
        }
      ],
      "source": [
        "#  Intersection with the Highest Average Vehicle Count\n",
        "average_vehicle_count_per_intersection = df.groupby('intersection_name')['vehicle_count'].mean()\n",
        "highest_average_vehicle_count_intersection = average_vehicle_count_per_intersection.idxmax()\n",
        "highest_average_vehicle_count = average_vehicle_count_per_intersection.max()\n",
        "print(\"Intersection with Highest Average Vehicle Count\", highest_average_vehicle_count_intersection,\n",
        "    \"Highest Average Vehicle Count\", highest_average_vehicle_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PEfvP98-K9A",
        "outputId": "b8386f75-7557-4b20-9bc9-5a49d050e840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Speed per Intersection intersection_name\n",
            "Allahabad Junction    33.821222\n",
            "Chowk                 33.465576\n",
            "Civil Lines           33.054770\n",
            "Jhunsi                33.778751\n",
            "Katra                 33.606356\n",
            "MNNIT Gate            34.110743\n",
            "Minto Park            32.918078\n",
            "Naini Bridge          33.895822\n",
            "Phaphamau             33.871509\n",
            "Tagore Town           33.734859\n",
            "Name: average_speed, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Compute Average Speed per Intersection\n",
        "average_speed_per_intersection = df.groupby('intersection_name')['average_speed'].mean()\n",
        "print(\"Average Speed per Intersection\", average_speed_per_intersection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU24lWIG-HYz",
        "outputId": "1e28fe47-6479-4dc5-a727-a6ca1b609bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weekend Data        record_id           timestamp  intersection_id   intersection_name  \\\n",
            "0              1 2023-01-01 00:00:00                1         Civil Lines   \n",
            "1              2 2023-01-01 00:00:00                2               Katra   \n",
            "2              3 2023-01-01 00:00:00                3               Chowk   \n",
            "3              4 2023-01-01 00:00:00                4         Tagore Town   \n",
            "4              5 2023-01-01 00:00:00                5        Naini Bridge   \n",
            "...          ...                 ...              ...                 ...   \n",
            "9896        9897 2023-01-07 23:50:00                7           Phaphamau   \n",
            "478          479 2023-01-07 23:50:00                9          MNNIT Gate   \n",
            "375          376 2023-01-07 23:50:00                6  Allahabad Junction   \n",
            "10078      10079 2023-01-07 23:50:00                9          MNNIT Gate   \n",
            "10079      10080 2023-01-07 23:50:00               10          Minto Park   \n",
            "\n",
            "       latitude  longitude  vehicle_count  average_speed  signal_cycle_time  \\\n",
            "0       25.4486    81.8333           51.0          46.52                120   \n",
            "1       25.4550    81.8463           73.0          38.59                120   \n",
            "2       25.4314    81.8437           65.0          38.61                120   \n",
            "3       25.4675    81.8867           54.0          44.05                120   \n",
            "4       25.4088    81.8592           30.0          49.09                120   \n",
            "...         ...        ...            ...            ...                ...   \n",
            "9896    25.4945    81.8686          156.0          30.01                120   \n",
            "478     25.4920    81.8639          112.0          30.98                120   \n",
            "375     25.4358    81.8307           46.0          34.56                120   \n",
            "10078   25.4920    81.8639          110.0          32.23                120   \n",
            "10079   25.4352    81.8820           51.0          41.71                120   \n",
            "\n",
            "       green_time  ...  red_time  weather_condition day_of_week is_holiday  \\\n",
            "0              63  ...        53              Clear      Sunday          1   \n",
            "1              57  ...        59              Clear      Sunday          1   \n",
            "2              58  ...        57              Clear      Sunday          1   \n",
            "3              58  ...        58              Clear      Sunday          1   \n",
            "4              59  ...        58              Clear      Sunday          1   \n",
            "...           ...  ...       ...                ...         ...        ...   \n",
            "9896           82  ...        33              Clear    Saturday          0   \n",
            "478            57  ...        57         Light Rain      Sunday          0   \n",
            "375            57  ...        58                Fog      Sunday          0   \n",
            "10078          64  ...        51          Cold Wave    Saturday          0   \n",
            "10079          61  ...        54          Cold Wave    Saturday          0   \n",
            "\n",
            "                      event pollution_level  car_count  bus_count  \\\n",
            "0      New Year Celebration            0.84         34          3   \n",
            "1      New Year Celebration            1.54         38          7   \n",
            "2                   unknown            1.05         41          3   \n",
            "3                   unknown            1.18         36          7   \n",
            "4                   unknown            0.44         20          0   \n",
            "...                     ...             ...        ...        ...   \n",
            "9896                unknown            2.91         90         13   \n",
            "478                 unknown            2.30         63         13   \n",
            "375                 unknown            0.98         32          7   \n",
            "10078               unknown            2.45         51          9   \n",
            "10079               unknown            0.81         31          2   \n",
            "\n",
            "       truck_count  motorcycle_count  \n",
            "0                4                10  \n",
            "1               10                18  \n",
            "2                6                15  \n",
            "3                5                 6  \n",
            "4                4                 6  \n",
            "...            ...               ...  \n",
            "9896            15                38  \n",
            "478             10                26  \n",
            "375              2                 5  \n",
            "10078           21                29  \n",
            "10079            5                13  \n",
            "\n",
            "[2852 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "# Retrieve Weekend Data (Saturday or Sunday)\n",
        "weekend_data = df[df['day_of_week'].isin(['Saturday', 'Sunday'])]\n",
        "print(\"Weekend Data\", weekend_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaczmIEn9-Jb",
        "outputId": "bde57601-691c-4769-b425-672efd2e5a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Vehicle Count per Hour hour\n",
            "0      83.780723\n",
            "1      78.851319\n",
            "2      83.023981\n",
            "3      82.828162\n",
            "4      87.004819\n",
            "5      85.658654\n",
            "6      83.109489\n",
            "7     160.966019\n",
            "8     165.616307\n",
            "9     157.810680\n",
            "10    156.019185\n",
            "11     79.842995\n",
            "12     85.810096\n",
            "13     86.202410\n",
            "14     83.874396\n",
            "15     81.458234\n",
            "16     85.503580\n",
            "17    162.867788\n",
            "18    162.620525\n",
            "19    167.688995\n",
            "20    166.415865\n",
            "21     81.282297\n",
            "22     81.454327\n",
            "23     89.384766\n",
            "Name: vehicle_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Average Vehicle Count per Hour Across All Intersections\n",
        "# Assuming 'timestamp' column includes time information\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "average_vehicle_count_per_hour = df.groupby('hour')['vehicle_count'].mean()\n",
        "print(\"Average Vehicle Count per Hour\", average_vehicle_count_per_hour)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5iFMbR1-B6u",
        "outputId": "b52037da-6165-45cc-a744-effc9c5961a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rainy Weather Data       record_id           timestamp  intersection_id   intersection_name  \\\n",
            "40           41 2023-01-01 00:40:00                1         Civil Lines   \n",
            "41           42 2023-01-01 00:40:00                2               Katra   \n",
            "42           43 2023-01-01 00:40:00                3               Chowk   \n",
            "43           44 2023-01-01 00:40:00                4         Tagore Town   \n",
            "45           46 2023-01-01 00:40:00                6  Allahabad Junction   \n",
            "...         ...                 ...              ...                 ...   \n",
            "478         479 2023-01-07 23:50:00                9          MNNIT Gate   \n",
            "5358       5359 2023-01-07 23:50:00                9          MNNIT Gate   \n",
            "5887       5888 2023-01-07 23:50:00                8              Jhunsi   \n",
            "7125       7126 2023-01-07 23:50:00                6  Allahabad Junction   \n",
            "7457       7458 2023-01-07 23:50:00                8              Jhunsi   \n",
            "\n",
            "      latitude  longitude  vehicle_count  average_speed  signal_cycle_time  \\\n",
            "40     25.4486    81.8333           64.0          38.84                120   \n",
            "41     25.4550    81.8463           62.0          36.57                120   \n",
            "42     25.4314    81.8437           44.0          41.34                120   \n",
            "43     25.4675    81.8867           14.0          51.44                120   \n",
            "45     25.4358    81.8307           39.0          40.85                120   \n",
            "...        ...        ...            ...            ...                ...   \n",
            "478    25.4920    81.8639          112.0          30.98                120   \n",
            "5358   25.4920    81.8639          101.0          27.62                120   \n",
            "5887   25.4326    81.9061           73.0          36.81                120   \n",
            "7125   25.4358    81.8307           30.0          43.64                120   \n",
            "7457   25.4326    81.9061          104.0          29.64                120   \n",
            "\n",
            "      green_time  ...  weather_condition  day_of_week is_holiday  \\\n",
            "40            60  ...         Light Rain       Sunday          1   \n",
            "41            64  ...         Light Rain       Sunday          1   \n",
            "42            58  ...         Light Rain       Sunday          1   \n",
            "43            66  ...         Light Rain       Sunday          1   \n",
            "45            61  ...         Light Rain       Sunday          1   \n",
            "...          ...  ...                ...          ...        ...   \n",
            "478           57  ...         Light Rain       Sunday          0   \n",
            "5358          54  ...         Heavy Rain    Wednesday          0   \n",
            "5887          59  ...         Light Rain     Thursday          0   \n",
            "7125          60  ...         Light Rain     Thursday          0   \n",
            "7457          62  ...         Light Rain       Friday          0   \n",
            "\n",
            "                     event  pollution_level car_count  bus_count  truck_count  \\\n",
            "40    New Year Celebration             1.24        38          8            3   \n",
            "41    New Year Celebration             1.15        38          5            6   \n",
            "42                 unknown             0.76        28          4            2   \n",
            "43                 unknown             1.95         7          2            3   \n",
            "45                 unknown             0.94        21          7            3   \n",
            "...                    ...              ...       ...        ...          ...   \n",
            "478                unknown             2.30        63         13           10   \n",
            "5358               unknown             2.90        50         23           11   \n",
            "5887               unknown             1.18        49          5            4   \n",
            "7125               unknown             0.74        18          5            3   \n",
            "7457               unknown             2.07        59         10           11   \n",
            "\n",
            "      motorcycle_count  hour  \n",
            "40                  15     0  \n",
            "41                  13     0  \n",
            "42                  10     0  \n",
            "43                   2     0  \n",
            "45                   8     0  \n",
            "...                ...   ...  \n",
            "478                 26    23  \n",
            "5358                17    23  \n",
            "5887                15    23  \n",
            "7125                 4    23  \n",
            "7457                24    23  \n",
            "\n",
            "[1474 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "#  Data for Rainy Weather Conditions\n",
        "rainy_weather_data = df[df['weather_condition'].isin(['Light Rain', 'Heavy Rain'])]\n",
        "print(    \"Rainy Weather Data\", rainy_weather_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpK85IbFtewj",
        "outputId": "fffc01d9-ed74-4f3a-e93d-d5fa38ebfd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total vehicle avgerage city 1097.5992063492063\n",
            "average speed per intersection 33.625768880396855\n"
          ]
        }
      ],
      "source": [
        "total_vehicle_avg_city= total_vehicle_count_per_day.mean()\n",
        "print(\"total vehicle avgerage city\", total_vehicle_avg_city)\n",
        "average_speed_per_intersection=average_speed_per_intersection.mean()\n",
        "print(\"average speed per intersection\",average_speed_per_intersection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y-CQXtvlpTZm",
        "outputId": "e77288c8-36c1-45d4-a9cd-10208241ec39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Daily Traffic Volume per Intersection:\n",
            "intersection_id\n",
            "1     112.522750\n",
            "2     113.209302\n",
            "3     111.853387\n",
            "4     111.118182\n",
            "5     110.402427\n",
            "6     110.997982\n",
            "7     109.011179\n",
            "8     119.436309\n",
            "9     107.385700\n",
            "10    111.901623\n",
            "Name: vehicle_count, dtype: float64\n",
            "\n",
            "Average Speed per Intersection:\n",
            "intersection_id\n",
            "1     33.046309\n",
            "2     33.638918\n",
            "3     33.454269\n",
            "4     33.757568\n",
            "5     33.896817\n",
            "6     33.841419\n",
            "7     33.889719\n",
            "8     33.660530\n",
            "9     34.139880\n",
            "10    32.904679\n",
            "Name: average_speed, dtype: float64\n",
            "\n",
            "Average Wait Time per Intersection:\n",
            "intersection_id\n",
            "1     51.524574\n",
            "2     51.433868\n",
            "3     51.694389\n",
            "4     51.719720\n",
            "5     51.776777\n",
            "6     51.628372\n",
            "7     51.775100\n",
            "8     51.626484\n",
            "9     52.171171\n",
            "10    51.430862\n",
            "dtype: float64\n",
            "\n",
            "Average Pollution Level per Intersection:\n",
            "intersection_id\n",
            "1     2.254132\n",
            "2     2.256273\n",
            "3     2.250371\n",
            "4     2.228398\n",
            "5     2.188178\n",
            "6     2.217652\n",
            "7     2.174990\n",
            "8     2.210521\n",
            "9     2.145946\n",
            "10    2.225591\n",
            "Name: pollution_level, dtype: float64\n",
            "\n",
            "Vehicle Type Distribution per Intersection:\n",
            "                 car_count  bus_count  truck_count  motorcycle_count\n",
            "intersection_id                                                     \n",
            "1                 0.601267   0.100999     0.099839          0.197895\n",
            "2                 0.601646   0.100524     0.098777          0.199053\n",
            "3                 0.597674   0.100791     0.099535          0.202000\n",
            "4                 0.600265   0.099607     0.100198          0.199930\n",
            "5                 0.601916   0.098377     0.100888          0.198819\n",
            "6                 0.601302   0.100319     0.099670          0.198708\n",
            "7                 0.600988   0.100203     0.099501          0.199307\n",
            "8                 0.597746   0.100797     0.100118          0.201338\n",
            "9                 0.600742   0.100052     0.099036          0.200170\n",
            "10                0.599300   0.099602     0.101041          0.200058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_11420\\454578130.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  average_wait_time =df.groupby('intersection_id').apply(lambda x: x['red_time'].mean())\n"
          ]
        }
      ],
      "source": [
        "daily_traffic_volume = df.groupby(['intersection_id', 'timestamp'])['vehicle_count'].sum().groupby('intersection_id').mean()\n",
        "average_speed_per_intersection = df.groupby('intersection_id')['average_speed'].mean()\n",
        "average_wait_time =df.groupby('intersection_id').apply(lambda x: x['red_time'].mean())\n",
        "average_pollution_level = df.groupby('intersection_id')['pollution_level'].mean()\n",
        "vehicle_type_distribution = df.groupby('intersection_id')[['car_count', 'bus_count', 'truck_count', 'motorcycle_count']].mean()\n",
        "vehicle_type_distribution = vehicle_type_distribution.div(vehicle_type_distribution.sum(axis=1), axis=0)\n",
        "print(\"Daily Traffic Volume per Intersection:\")\n",
        "print(daily_traffic_volume)\n",
        "print(\"\\nAverage Speed per Intersection:\")\n",
        "print(average_speed_per_intersection)\n",
        "print(\"\\nAverage Wait Time per Intersection:\")\n",
        "print(average_wait_time)\n",
        "print(\"\\nAverage Pollution Level per Intersection:\")\n",
        "print(average_pollution_level)\n",
        "print(\"\\nVehicle Type Distribution per Intersection:\")\n",
        "print(vehicle_type_distribution)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei6_fXbAqgOe",
        "outputId": "1cccefd2-48e2-49b5-fa1d-da74ece4eb75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Pollution Level: 2.2152052244088885\n",
            "Average Car Count: 66.52372808078016\n",
            "Average Bus Count: 11.096551587567442\n",
            "Average Truck Count: 11.066688208439977\n",
            "Average Motorcycle Count: 22.13392209528245\n"
          ]
        }
      ],
      "source": [
        "avg_pollution_level = df.groupby('intersection_id')['pollution_level'].mean().mean()\n",
        "avg_car_count = df.groupby('intersection_id')['car_count'].mean().mean()\n",
        "avg_bus_count = df.groupby('intersection_id')['bus_count'].mean().mean()\n",
        "avg_truck_count = df.groupby('intersection_id')['truck_count'].mean().mean()\n",
        "avg_motorcycle_count = df.groupby('intersection_id')['motorcycle_count'].mean().mean()\n",
        "print(\"Average Pollution Level:\", avg_pollution_level)\n",
        "print(\"Average Car Count:\", avg_car_count)\n",
        "print(\"Average Bus Count:\", avg_bus_count)\n",
        "print(\"Average Truck Count:\", avg_truck_count)\n",
        "print(\"Average Motorcycle Count:\", avg_motorcycle_count)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtoMME0PxDK8",
        "outputId": "3015dae1-c4ef-48e3-e2ed-1d70c9267619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    intersection_name  average_vehicles\n",
            "0  Allahabad Junction        111.140281\n",
            "1               Chowk        112.312779\n",
            "2         Civil Lines        112.055000\n",
            "3              Jhunsi        109.573011\n",
            "4               Katra        113.240240\n",
            "5          MNNIT Gate        107.530120\n",
            "6          Minto Park        111.040241\n",
            "7        Naini Bridge        110.068618\n",
            "8           Phaphamau        108.857143\n",
            "9         Tagore Town        112.132530\n",
            "overall mean 110.79499636123751\n"
          ]
        }
      ],
      "source": [
        "df['total_vehicles'] = df['car_count'] + df['bus_count'] + df['truck_count'] + df['motorcycle_count']\n",
        "\n",
        "# Group by intersection and calculate the average total vehicles\n",
        "average_vehicles = df.groupby('intersection_name')['total_vehicles'].mean().reset_index()\n",
        "\n",
        "# Display results\n",
        "average_vehicles.rename(columns={'total_vehicles': 'average_vehicles'}, inplace=True)\n",
        "print(average_vehicles)\n",
        "overall_mean=average_vehicles['average_vehicles'].mean()\n",
        "print(\"overall mean\",overall_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfaofsC7ya4u",
        "outputId": "d362480a-5e74-4bed-9cd9-41bd82a956c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average traffic by weather conditions:\n",
            "  weather_condition  total_vehicles\n",
            "0             Clear      115.345636\n",
            "1         Cold Wave      106.466245\n",
            "2               Fog       92.370450\n",
            "3          Heatwave      112.506550\n",
            "4        Heavy Rain       79.353414\n",
            "5        Light Rain      103.565574\n",
            "\n",
            "Weather type with the least traffic:\n",
            "weather_condition    Heavy Rain\n",
            "total_vehicles        79.353414\n",
            "Name: 4, dtype: object\n"
          ]
        }
      ],
      "source": [
        "df['total_vehicles'] = df['car_count'] + df['bus_count'] + df['truck_count'] + df['motorcycle_count']\n",
        "\n",
        "# Group by weather conditions and calculate average total vehicles\n",
        "weather_traffic_summary = df.groupby('weather_condition')['total_vehicles'].mean().reset_index()\n",
        "\n",
        "# Find the weather type with the least traffic\n",
        "least_traffic_weather = weather_traffic_summary.loc[weather_traffic_summary['total_vehicles'].idxmin()]\n",
        "\n",
        "# Display results\n",
        "print(\"Average traffic by weather conditions:\")\n",
        "print(weather_traffic_summary)\n",
        "print(\"\\nWeather type with the least traffic:\")\n",
        "print(least_traffic_weather)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idE-_LAEt6DG",
        "outputId": "55c1b664-298a-47fc-cc7d-25cadf8fb541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "intersection_name\n",
            "Allahabad Junction    2.226212\n",
            "Chowk                 2.245612\n",
            "Civil Lines           2.246630\n",
            "Jhunsi                2.193374\n",
            "Katra                 2.261281\n",
            "MNNIT Gate            2.149066\n",
            "Minto Park            2.221217\n",
            "Naini Bridge          2.190848\n",
            "Phaphamau             2.178612\n",
            "Tagore Town           2.234418\n",
            "Name: pollution_level, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "avg_pollution_level_intersection = df.groupby('intersection_name')['pollution_level'].mean()\n",
        "print(avg_pollution_level_intersection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWmEHiadhZcB"
      },
      "source": [
        "Adding Extra Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoclxgWMhr4-"
      },
      "source": [
        "1. Average vehicle count during morning and evening peak hours for every intersection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dan_nla6hYhv",
        "outputId": "677c8795-d41e-49d9-ee67-1a5d07e31839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   intersection_id  hour  vehicle_count\n",
            "0                1     7     165.238095\n",
            "1                1     8     170.146341\n",
            "2                1     9     154.500000\n",
            "3                1    10     164.500000\n",
            "4                1    17     172.585366\n"
          ]
        }
      ],
      "source": [
        "# morning and evening peak hours\n",
        "peak_hours = df[(df['hour'].between(7, 10)) | (df['hour'].between(17, 20))]\n",
        "\n",
        "# Calculate average vehicle count by intersection and hour during peak hours\n",
        "peak_hour_avg = peak_hours.groupby(['intersection_id', 'hour'])['vehicle_count'].mean().reset_index()\n",
        "print(peak_hour_avg.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEFXX0tojt8R"
      },
      "source": [
        "2.variance in average speeds across intersections and understanding how it is related to green light time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxboiNFMj1-x",
        "outputId": "447540b9-53be-489c-e42d-148bd73a20c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   intersection_id  green_time  speed_variance\n",
            "0                1          63       53.558675\n",
            "1                2          57       44.697690\n",
            "2                3          58       66.457640\n",
            "3                4          58       50.380460\n",
            "4                5          59       50.440565\n"
          ]
        }
      ],
      "source": [
        "# Calculate variance of average speed by intersection\n",
        "speed_variance = df.groupby('intersection_id')['average_speed'].var().reset_index()\n",
        "speed_variance = speed_variance.rename(columns={'average_speed': 'speed_variance'})\n",
        "\n",
        "# Merge speed variance with green_time information\n",
        "# Assuming 'green_time' does not vary within each intersection\n",
        "signal_info = df[['intersection_id', 'green_time']].drop_duplicates()\n",
        "speed_and_signal = signal_info.merge(speed_variance, on='intersection_id')\n",
        "\n",
        "print(speed_and_signal.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuZTfG8EkuQT"
      },
      "source": [
        "3.Average pollution level under different weather conditions as well as holidays and non holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK8G0Frmk5fA",
        "outputId": "d9acd304-d911-451e-ef70-39e523e86c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  weather_condition  pollution_level\n",
            "0             Clear         2.303541\n",
            "1         Cold Wave         2.142405\n",
            "2               Fog         1.871349\n",
            "3          Heatwave         2.249629\n",
            "4        Heavy Rain         1.602410\n",
            "    is_holiday  pollution_level\n",
            "0  Non-Holiday         2.354647\n",
            "1      Holiday         1.372075\n"
          ]
        }
      ],
      "source": [
        "# average pollution level by weather condition\n",
        "weather_pollution_avg =df.groupby('weather_condition')['pollution_level'].mean().reset_index()\n",
        "# Calculate average pollution level on holidays vs non-holidays\n",
        "holiday_pollution_avg = df.groupby('is_holiday')['pollution_level'].mean().reset_index()\n",
        "holiday_pollution_avg['is_holiday'] = holiday_pollution_avg['is_holiday'].map({1: 'Holiday', 0: 'Non-Holiday'})\n",
        "\n",
        "print(weather_pollution_avg.head())\n",
        "print(holiday_pollution_avg.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rb076nUlK4Z"
      },
      "source": [
        "4.which intersections get busier on event days compared to regular days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCRETnwIlnTW",
        "outputId": "d11aae64-9356-4cea-cefa-1e78876ad2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  event  vehicle_count\n",
            "0              Accident     134.923077\n",
            "1     Local Market Fair     146.419118\n",
            "2  New Year Celebration      91.819444\n",
            "3              Roadwork     157.928962\n",
            "4               unknown     107.963449\n"
          ]
        }
      ],
      "source": [
        "# average vehicle count by event type\n",
        "event_vehicle_avg = df.groupby('event')['vehicle_count'].mean().reset_index()\n",
        "print(event_vehicle_avg.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP3AzVjal3iy"
      },
      "source": [
        "5. traffic compositions at intersections also identify those intersection with high percentage of vehicles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbwusXIGl2Lo",
        "outputId": "810e1617-aac8-4bb9-bbf0-11082c006f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   intersection_id  car_count_percentage  bus_count_percentage  \\\n",
            "0                1             60.017263             10.214140   \n",
            "1                2             60.248227             10.002216   \n",
            "2                3             59.673720             10.106246   \n",
            "3                4             60.054101             10.021427   \n",
            "4                5             60.027549              9.897375   \n",
            "\n",
            "   truck_count_percentage  motorcycle_count_percentage  \n",
            "0               10.006908                    19.761689  \n",
            "1                9.800417                    19.949140  \n",
            "2                9.984376                    20.235659  \n",
            "3               10.003333                    19.921139  \n",
            "4               10.152022                    19.923054  \n"
          ]
        }
      ],
      "source": [
        "# Calculate percentage of each vehicle type for each intersection\n",
        "vehicle_types = ['car_count', 'bus_count', 'truck_count', 'motorcycle_count']\n",
        "df['total_vehicles'] = df[vehicle_types].sum(axis=1)\n",
        "\n",
        "#  proportion of each vehicle type at each intersection\n",
        "for vehicle in vehicle_types:\n",
        "    df[f'{vehicle}_percentage'] = (df[vehicle] / df['total_vehicles']) * 100\n",
        "\n",
        "# average distribution by intersection\n",
        "vehicle_distribution = df.groupby('intersection_id')[[f'{v}_percentage' for v in vehicle_types]].mean().reset_index()\n",
        "\n",
        "print(vehicle_distribution.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciMwOe3_oFsW"
      },
      "source": [
        "DATA FOR PROBLEM IN TRAFFIC CONGESTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4GQL8Jb2oMza",
        "outputId": "f45e4996-f255-45a5-a40d-54c5d25b2fd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>car_count</th>\n",
              "      <th>bus_count</th>\n",
              "      <th>truck_count</th>\n",
              "      <th>motorcycle_count</th>\n",
              "      <th>green_time</th>\n",
              "      <th>red_time</th>\n",
              "      <th>average_speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "      <td>10080.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>66.518056</td>\n",
              "      <td>11.096726</td>\n",
              "      <td>11.066468</td>\n",
              "      <td>22.134623</td>\n",
              "      <td>63.822123</td>\n",
              "      <td>51.677679</td>\n",
              "      <td>33.623533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36.618756</td>\n",
              "      <td>6.853814</td>\n",
              "      <td>6.807091</td>\n",
              "      <td>12.763979</td>\n",
              "      <td>9.470672</td>\n",
              "      <td>9.514600</td>\n",
              "      <td>7.294070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>14.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>28.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>59.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>33.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>84.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>38.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>269.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>52.530000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          car_count     bus_count   truck_count  motorcycle_count  \\\n",
              "count  10080.000000  10080.000000  10080.000000      10080.000000   \n",
              "mean      66.518056     11.096726     11.066468         22.134623   \n",
              "std       36.618756      6.853814      6.807091         12.763979   \n",
              "min        0.000000      0.000000      0.000000          0.000000   \n",
              "25%       40.000000      6.000000      6.000000         13.000000   \n",
              "50%       59.000000     10.000000     10.000000         19.000000   \n",
              "75%       84.000000     15.000000     15.000000         29.000000   \n",
              "max      269.000000     51.000000     48.000000         93.000000   \n",
              "\n",
              "         green_time      red_time  average_speed  \n",
              "count  10080.000000  10080.000000   10080.000000  \n",
              "mean      63.822123     51.677679      33.623533  \n",
              "std        9.470672      9.514600       7.294070  \n",
              "min       40.000000     19.000000      14.610000  \n",
              "25%       57.000000     48.000000      28.830000  \n",
              "50%       61.000000     54.000000      33.600000  \n",
              "75%       68.000000     58.000000      38.310000  \n",
              "max       96.000000     74.000000      52.530000  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "road_safety_data = df[['car_count', 'bus_count', 'truck_count', 'motorcycle_count', 'green_time', 'red_time','average_speed']]\n",
        "\n",
        "# Display a summary of the extracted data to analyze key road safety metrics\n",
        "road_safety_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ-b72YsAlwJ"
      },
      "source": [
        "Implement RANDOM FOREST to predict the feature of congestion based on many features like holiday , day of week ,etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\chinm\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\chinm\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chinm\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chinm\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Using cached scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.6.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoJizyAkBj0s",
        "outputId": "0db9c8d2-de28-4fcb-afa3-fb6e301830d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1.9830704365079368, 30.03174429563492, np.float64(5.480122653338602))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Selecting relevant features for regression so as to improve the speed of model further\n",
        "data_clean = df[['day_of_week', 'is_holiday', 'average_speed', 'signal_cycle_time', 'green_time', 'yellow_time', 'red_time', 'weather_condition',\n",
        "                   'pollution_level', 'car_count', 'bus_count', 'truck_count',\n",
        "                   'motorcycle_count', 'vehicle_count']].dropna()\n",
        "\n",
        "# converting categorial values into integers\n",
        "label_enc = LabelEncoder()\n",
        "data_clean['day_of_week'] = label_enc.fit_transform(data_clean['day_of_week'])\n",
        "data_clean['weather_condition'] = label_enc.fit_transform(data_clean['weather_condition'])\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data_clean.drop('vehicle_count', axis=1)\n",
        "y = data_clean['vehicle_count']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mae, mse, rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.pkl'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuDQvxBjWYT"
      },
      "source": [
        "Holiday Impact Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJePqAoKjWEx",
        "outputId": "c2399a4f-9a53-41b8-8016-9e7adda80624"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Holiday (is_holiday=1)': np.float64(68.56603773584905),\n",
              " 'Special Events': np.float64(118.33928571428571),\n",
              " 'Regular Days': np.float64(115.60654172137997)}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Separate data for holidays, special events, and regular days\n",
        "holiday_data = df[df['is_holiday'] == 1]\n",
        "event_data = df[df['event'].isin(['New Year Celebration', 'Local Market Fair'])]\n",
        "regular_day_data = df[(df['is_holiday'] != 1) &\n",
        "                                (~df['event'].isin(['New Year Celebration', 'Local Market Fair']))]\n",
        "\n",
        "# Calculate average vehicle count for holidays, events, and regular days\n",
        "holiday_event_impact = {\n",
        "    'Holiday (is_holiday=1)': holiday_data['vehicle_count'].mean(),\n",
        "    'Special Events': event_data['vehicle_count'].mean(),\n",
        "    'Regular Days': regular_day_data['vehicle_count'].mean()\n",
        "}\n",
        "\n",
        "holiday_event_impact\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YENt2bsfj7SL"
      },
      "source": [
        "Weather Impact analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mPlY3_xBj-jl",
        "outputId": "c939c3f5-6d60-4268-99d3-bcbf15b30111"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vehicle_count</th>\n",
              "      <th>average_speed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weather_condition</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Clear</th>\n",
              "      <td>113.960733</td>\n",
              "      <td>34.507329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fog</th>\n",
              "      <td>92.743041</td>\n",
              "      <td>29.695268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heavy Rain</th>\n",
              "      <td>79.546185</td>\n",
              "      <td>27.340763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Light Rain</th>\n",
              "      <td>103.609631</td>\n",
              "      <td>32.333648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   vehicle_count  average_speed\n",
              "weather_condition                              \n",
              "Clear                 113.960733      34.507329\n",
              "Fog                    92.743041      29.695268\n",
              "Heavy Rain             79.546185      27.340763\n",
              "Light Rain            103.609631      32.333648"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter data for relevant weather conditions: 'Clear', 'Light Rain', 'Heavy Rain', and 'Fog'\n",
        "weather_conditions_of_interest = ['Clear', 'Light Rain', 'Heavy Rain', 'Fog']\n",
        "weather_data = df[df['weather_condition'].isin(weather_conditions_of_interest)]\n",
        "\n",
        "# Group by weather condition and calculate mean vehicle count and average speed for each condition\n",
        "weather_impact_analysis = weather_data.groupby('weather_condition')[['vehicle_count', 'average_speed']].mean()\n",
        "\n",
        "# Display the analysis results\n",
        "weather_impact_analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxYDa89hkMm4"
      },
      "source": [
        "Correlation analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW9oz3r1kMPp",
        "outputId": "f02b66bf-19ac-44f7-8f65-a6e34f8f24f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(-0.7859519125048007)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  correlation coefficient between vehicle_count and average_speed\n",
        "correlation_analysis = df[['vehicle_count', 'average_speed']].corr().iloc[0,1]\n",
        "\n",
        "# Display the correlation result\n",
        "correlation_analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60M8nf2FktbF",
        "outputId": "78bbcb9f-9571-4fe5-bd6f-052794139634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation between vehicle_count and pollution_level: 0.9636716674269131\n"
          ]
        }
      ],
      "source": [
        "correlation = df['vehicle_count'].corr(df['pollution_level'])\n",
        "\n",
        "# Display the correlation result\n",
        "print(\"Correlation between vehicle_count and pollution_level:\", correlation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DfF9ExclDyN",
        "outputId": "65280edb-01dc-4fcb-c648-b8268f8aab93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlations with Vehicle Count (Congestion Indicator):\n",
            "vehicle_count      1.000000\n",
            "pollution_level    0.963672\n",
            "is_holiday        -0.293673\n",
            "average_speed     -0.785952\n",
            "Name: vehicle_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "columns_of_interest = ['vehicle_count', 'pollution_level', 'average_speed', 'is_holiday']\n",
        "correlation_data = df[columns_of_interest]\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = correlation_data.corr()\n",
        "\n",
        "# Extract correlations specifically with `vehicle_count`\n",
        "vehicle_count_corr = correlation_matrix['vehicle_count'].sort_values(ascending=False)\n",
        "\n",
        "# Display the correlation results\n",
        "print(\"Correlations with Vehicle Count (Congestion Indicator):\")\n",
        "print(vehicle_count_corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Clear', 'Light Rain', 'Heatwave', 'Cold Wave', 'Heavy Rain',\n",
              "       'Fog'], dtype=object)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"weather_condition\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
